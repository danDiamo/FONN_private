{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "outputs": [],
   "source": [
    "# TODO: Debug n-gram extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['0', '0', '0', '1', '1', '1', '7', '3', '3', '7', '5', '4', '5', '2', '6', '7', '5', '1', '0', '0', '0', '1', '1', '1'], ['7', '3', '3', '1', '1', '1', '2', '4', '6', '2', '4', '6', '5', '4', '5', '6', '1', '1', '1', '0', '0', '0'], ['7', '2', '2', '1', '1', '1', '3', '5', '7', '0', '0', '0', '4', '3', '5', '6', '1', '2', '3', '0', '0'], ['7', '0', '6', '1', '5', '1', '7', '5', '5', '7', '0', '0', '0', '2', '2', '7', '3', '1', '1', '1']]\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Setup toy corpus\n",
    "\n",
    "tune_1 = [0, 0, 0, 1, 1, 1, 7, 3, 3, 7, 5, 4, 5, 2, 6, 7, 5, 1, 0, 0, 0, 1, 1, 1]\n",
    "tune_2 = [7, 3, 3, 1, 1, 1, 2, 4, 6, 2, 4, 6, 5, 4, 5, 6, 1, 1, 1, 0, 0, 0]\n",
    "tune_3 = [7, 2, 2, 1, 1, 1, 3, 5, 7, 0, 0, 0, 4, 3, 5, 6, 1, 2, 3, 0, 0]\n",
    "tune_4 = [7, 0, 6, 1, 5, 1, 7, 5, 5, 7, 0, 0, 0, 2, 2, 7, 3, 1, 1, 1]\n",
    "tunes = [tune_1, tune_2, tune_3, tune_4]\n",
    "\n",
    "import numpy as np\n",
    "corpus = []\n",
    "for t in tunes:\n",
    "    t_reformatted = [str(i) for i in t]\n",
    "    corpus.append(t_reformatted)\n",
    "\n",
    "print(corpus)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dannydiamond/NUIG/Polifonia/repo/FONN_private/venv/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "# Step 2: Test implementation of CountVectorizer per SKLearn docs.\n",
    "# NOTE: This uses updated SKLearn package; and initializes correctly per the docs.\n",
    "\n",
    "vec = CountVectorizer(input='content', lowercase=False, tokenizer=lambda x: x, ngram_range=(3,6), min_df=1, analyzer='word')\n",
    "# corpus_vec = CountVectorizer(input='content', analyzer='word', ngram_range=(3, 9), lowercase=False, tokenizer=lambda x: x, min_df=1)\n",
    "# store all n-gram pattern freqs:\n",
    "freq = vec.fit_transform(corpus)\n",
    "# store all unique n-gram patterns:\n",
    "feat_names = vec.get_feature_names_out()\n",
    "patterns = np.array([np.array([int(float(ch.strip())) for ch in p.split()], dtype='int16') for p in feat_names], dtype='object')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0\n",
      "0 0 0 1\n",
      "0 0 0 1 1\n",
      "0 0 0 1 1 1\n",
      "0 0 0 2\n",
      "0 0 0 2 2\n",
      "0 0 0 2 2 7\n",
      "0 0 0 4\n",
      "0 0 0 4 3\n",
      "0 0 0 4 3 5\n",
      "0 0 1\n",
      "0 0 1 1\n",
      "0 0 1 1 1\n",
      "0 0 1 1 1 7\n",
      "0 0 2\n",
      "0 0 2 2\n",
      "0 0 2 2 7\n",
      "0 0 2 2 7 3\n",
      "0 0 4\n",
      "0 0 4 3\n",
      "0 0 4 3 5\n",
      "0 0 4 3 5 6\n",
      "0 1 1\n",
      "0 1 1 1\n",
      "0 1 1 1 7\n",
      "0 1 1 1 7 3\n",
      "0 2 2\n",
      "0 2 2 7\n",
      "0 2 2 7 3\n",
      "0 2 2 7 3 1\n",
      "0 4 3\n",
      "0 4 3 5\n",
      "0 4 3 5 6\n",
      "0 4 3 5 6 1\n",
      "0 6 1\n",
      "0 6 1 5\n",
      "0 6 1 5 1\n",
      "0 6 1 5 1 7\n",
      "1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0 1\n",
      "1 0 0 0 1 1\n",
      "1 1 0\n",
      "1 1 0 0\n",
      "1 1 0 0 0\n",
      "1 1 1\n",
      "1 1 1 0\n",
      "1 1 1 0 0\n",
      "1 1 1 0 0 0\n",
      "1 1 1 2\n",
      "1 1 1 2 4\n",
      "1 1 1 2 4 6\n",
      "1 1 1 3\n",
      "1 1 1 3 5\n",
      "1 1 1 3 5 7\n",
      "1 1 1 7\n",
      "1 1 1 7 3\n",
      "1 1 1 7 3 3\n",
      "1 1 2\n",
      "1 1 2 4\n",
      "1 1 2 4 6\n",
      "1 1 2 4 6 2\n",
      "1 1 3\n",
      "1 1 3 5\n",
      "1 1 3 5 7\n",
      "1 1 3 5 7 0\n",
      "1 1 7\n",
      "1 1 7 3\n",
      "1 1 7 3 3\n",
      "1 1 7 3 3 7\n",
      "1 2 3\n",
      "1 2 3 0\n",
      "1 2 3 0 0\n",
      "1 2 4\n",
      "1 2 4 6\n",
      "1 2 4 6 2\n",
      "1 2 4 6 2 4\n",
      "1 3 5\n",
      "1 3 5 7\n",
      "1 3 5 7 0\n",
      "1 3 5 7 0 0\n",
      "1 5 1\n",
      "1 5 1 7\n",
      "1 5 1 7 5\n",
      "1 5 1 7 5 5\n",
      "1 7 3\n",
      "1 7 3 3\n",
      "1 7 3 3 7\n",
      "1 7 3 3 7 5\n",
      "1 7 5\n",
      "1 7 5 5\n",
      "1 7 5 5 7\n",
      "1 7 5 5 7 0\n",
      "2 1 1\n",
      "2 1 1 1\n",
      "2 1 1 1 3\n",
      "2 1 1 1 3 5\n",
      "2 2 1\n",
      "2 2 1 1\n",
      "2 2 1 1 1\n",
      "2 2 1 1 1 3\n",
      "2 2 7\n",
      "2 2 7 3\n",
      "2 2 7 3 1\n",
      "2 2 7 3 1 1\n",
      "2 3 0\n",
      "2 3 0 0\n",
      "2 4 6\n",
      "2 4 6 2\n",
      "2 4 6 2 4\n",
      "2 4 6 2 4 6\n",
      "2 4 6 5\n",
      "2 4 6 5 4\n",
      "2 4 6 5 4 5\n",
      "2 6 7\n",
      "2 6 7 5\n",
      "2 6 7 5 1\n",
      "2 6 7 5 1 0\n",
      "2 7 3\n",
      "2 7 3 1\n",
      "2 7 3 1 1\n",
      "2 7 3 1 1 1\n",
      "3 0 0\n",
      "3 1 1\n",
      "3 1 1 1\n",
      "3 1 1 1 2\n",
      "3 1 1 1 2 4\n",
      "3 3 1\n",
      "3 3 1 1\n",
      "3 3 1 1 1\n",
      "3 3 1 1 1 2\n",
      "3 3 7\n",
      "3 3 7 5\n",
      "3 3 7 5 4\n",
      "3 3 7 5 4 5\n",
      "3 5 6\n",
      "3 5 6 1\n",
      "3 5 6 1 2\n",
      "3 5 6 1 2 3\n",
      "3 5 7\n",
      "3 5 7 0\n",
      "3 5 7 0 0\n",
      "3 5 7 0 0 0\n",
      "3 7 5\n",
      "3 7 5 4\n",
      "3 7 5 4 5\n",
      "3 7 5 4 5 2\n",
      "4 3 5\n",
      "4 3 5 6\n",
      "4 3 5 6 1\n",
      "4 3 5 6 1 2\n",
      "4 5 2\n",
      "4 5 2 6\n",
      "4 5 2 6 7\n",
      "4 5 2 6 7 5\n",
      "4 5 6\n",
      "4 5 6 1\n",
      "4 5 6 1 1\n",
      "4 5 6 1 1 1\n",
      "4 6 2\n",
      "4 6 2 4\n",
      "4 6 2 4 6\n",
      "4 6 2 4 6 5\n",
      "4 6 5\n",
      "4 6 5 4\n",
      "4 6 5 4 5\n",
      "4 6 5 4 5 6\n",
      "5 1 0\n",
      "5 1 0 0\n",
      "5 1 0 0 0\n",
      "5 1 0 0 0 1\n",
      "5 1 7\n",
      "5 1 7 5\n",
      "5 1 7 5 5\n",
      "5 1 7 5 5 7\n",
      "5 2 6\n",
      "5 2 6 7\n",
      "5 2 6 7 5\n",
      "5 2 6 7 5 1\n",
      "5 4 5\n",
      "5 4 5 2\n",
      "5 4 5 2 6\n",
      "5 4 5 2 6 7\n",
      "5 4 5 6\n",
      "5 4 5 6 1\n",
      "5 4 5 6 1 1\n",
      "5 5 7\n",
      "5 5 7 0\n",
      "5 5 7 0 0\n",
      "5 5 7 0 0 0\n",
      "5 6 1\n",
      "5 6 1 1\n",
      "5 6 1 1 1\n",
      "5 6 1 1 1 0\n",
      "5 6 1 2\n",
      "5 6 1 2 3\n",
      "5 6 1 2 3 0\n",
      "5 7 0\n",
      "5 7 0 0\n",
      "5 7 0 0 0\n",
      "5 7 0 0 0 2\n",
      "5 7 0 0 0 4\n",
      "6 1 1\n",
      "6 1 1 1\n",
      "6 1 1 1 0\n",
      "6 1 1 1 0 0\n",
      "6 1 2\n",
      "6 1 2 3\n",
      "6 1 2 3 0\n",
      "6 1 2 3 0 0\n",
      "6 1 5\n",
      "6 1 5 1\n",
      "6 1 5 1 7\n",
      "6 1 5 1 7 5\n",
      "6 2 4\n",
      "6 2 4 6\n",
      "6 2 4 6 5\n",
      "6 2 4 6 5 4\n",
      "6 5 4\n",
      "6 5 4 5\n",
      "6 5 4 5 6\n",
      "6 5 4 5 6 1\n",
      "6 7 5\n",
      "6 7 5 1\n",
      "6 7 5 1 0\n",
      "6 7 5 1 0 0\n",
      "7 0 0\n",
      "7 0 0 0\n",
      "7 0 0 0 2\n",
      "7 0 0 0 2 2\n",
      "7 0 0 0 4\n",
      "7 0 0 0 4 3\n",
      "7 0 6\n",
      "7 0 6 1\n",
      "7 0 6 1 5\n",
      "7 0 6 1 5 1\n",
      "7 2 2\n",
      "7 2 2 1\n",
      "7 2 2 1 1\n",
      "7 2 2 1 1 1\n",
      "7 3 1\n",
      "7 3 1 1\n",
      "7 3 1 1 1\n",
      "7 3 3\n",
      "7 3 3 1\n",
      "7 3 3 1 1\n",
      "7 3 3 1 1 1\n",
      "7 3 3 7\n",
      "7 3 3 7 5\n",
      "7 3 3 7 5 4\n",
      "7 5 1\n",
      "7 5 1 0\n",
      "7 5 1 0 0\n",
      "7 5 1 0 0 0\n",
      "7 5 4\n",
      "7 5 4 5\n",
      "7 5 4 5 2\n",
      "7 5 4 5 2 6\n",
      "7 5 5\n",
      "7 5 5 7\n",
      "7 5 5 7 0\n",
      "7 5 5 7 0 0\n",
      "262\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# verify there are no duplicates in output:\n",
    "for p in feat_names:\n",
    "    print(p)\n",
    "print(len(feat_names))\n",
    "print(len(feat_names) == len(set(feat_names)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "outputs": [],
   "source": [
    "# compare vs our original implementation"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/dannydiamond/NUIG/Polifonia/repo/FONN_private/venv/lib/python3.10/site-packages/sklearn/feature_extraction/text.py:528: UserWarning: The parameter 'token_pattern' will not be used since 'tokenizer' is not None'\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "vec_2 = CountVectorizer(input='content', lowercase=False, tokenizer=lambda x: x, ngram_range=(3,6), min_df=1, analyzer='word')\n",
    "# store all n-gram pattern freqs:\n",
    "freq_2 = vec_2.fit_transform(corpus)\n",
    "# store all unique n-gram patterns:\n",
    "feat_names_2 = vec_2.get_feature_names_out()\n",
    "patterns_2 = np.array([np.array([int(float(ch.strip())) for ch in p.split()], dtype='int16') for p in feat_names_2], dtype='object')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0 0\n",
      "0 0 0 1\n",
      "0 0 0 1 1\n",
      "0 0 0 1 1 1\n",
      "0 0 0 2\n",
      "0 0 0 2 2\n",
      "0 0 0 2 2 7\n",
      "0 0 0 4\n",
      "0 0 0 4 3\n",
      "0 0 0 4 3 5\n",
      "0 0 1\n",
      "0 0 1 1\n",
      "0 0 1 1 1\n",
      "0 0 1 1 1 7\n",
      "0 0 2\n",
      "0 0 2 2\n",
      "0 0 2 2 7\n",
      "0 0 2 2 7 3\n",
      "0 0 4\n",
      "0 0 4 3\n",
      "0 0 4 3 5\n",
      "0 0 4 3 5 6\n",
      "0 1 1\n",
      "0 1 1 1\n",
      "0 1 1 1 7\n",
      "0 1 1 1 7 3\n",
      "0 2 2\n",
      "0 2 2 7\n",
      "0 2 2 7 3\n",
      "0 2 2 7 3 1\n",
      "0 4 3\n",
      "0 4 3 5\n",
      "0 4 3 5 6\n",
      "0 4 3 5 6 1\n",
      "0 6 1\n",
      "0 6 1 5\n",
      "0 6 1 5 1\n",
      "0 6 1 5 1 7\n",
      "1 0 0\n",
      "1 0 0 0\n",
      "1 0 0 0 1\n",
      "1 0 0 0 1 1\n",
      "1 1 0\n",
      "1 1 0 0\n",
      "1 1 0 0 0\n",
      "1 1 1\n",
      "1 1 1 0\n",
      "1 1 1 0 0\n",
      "1 1 1 0 0 0\n",
      "1 1 1 2\n",
      "1 1 1 2 4\n",
      "1 1 1 2 4 6\n",
      "1 1 1 3\n",
      "1 1 1 3 5\n",
      "1 1 1 3 5 7\n",
      "1 1 1 7\n",
      "1 1 1 7 3\n",
      "1 1 1 7 3 3\n",
      "1 1 2\n",
      "1 1 2 4\n",
      "1 1 2 4 6\n",
      "1 1 2 4 6 2\n",
      "1 1 3\n",
      "1 1 3 5\n",
      "1 1 3 5 7\n",
      "1 1 3 5 7 0\n",
      "1 1 7\n",
      "1 1 7 3\n",
      "1 1 7 3 3\n",
      "1 1 7 3 3 7\n",
      "1 2 3\n",
      "1 2 3 0\n",
      "1 2 3 0 0\n",
      "1 2 4\n",
      "1 2 4 6\n",
      "1 2 4 6 2\n",
      "1 2 4 6 2 4\n",
      "1 3 5\n",
      "1 3 5 7\n",
      "1 3 5 7 0\n",
      "1 3 5 7 0 0\n",
      "1 5 1\n",
      "1 5 1 7\n",
      "1 5 1 7 5\n",
      "1 5 1 7 5 5\n",
      "1 7 3\n",
      "1 7 3 3\n",
      "1 7 3 3 7\n",
      "1 7 3 3 7 5\n",
      "1 7 5\n",
      "1 7 5 5\n",
      "1 7 5 5 7\n",
      "1 7 5 5 7 0\n",
      "2 1 1\n",
      "2 1 1 1\n",
      "2 1 1 1 3\n",
      "2 1 1 1 3 5\n",
      "2 2 1\n",
      "2 2 1 1\n",
      "2 2 1 1 1\n",
      "2 2 1 1 1 3\n",
      "2 2 7\n",
      "2 2 7 3\n",
      "2 2 7 3 1\n",
      "2 2 7 3 1 1\n",
      "2 3 0\n",
      "2 3 0 0\n",
      "2 4 6\n",
      "2 4 6 2\n",
      "2 4 6 2 4\n",
      "2 4 6 2 4 6\n",
      "2 4 6 5\n",
      "2 4 6 5 4\n",
      "2 4 6 5 4 5\n",
      "2 6 7\n",
      "2 6 7 5\n",
      "2 6 7 5 1\n",
      "2 6 7 5 1 0\n",
      "2 7 3\n",
      "2 7 3 1\n",
      "2 7 3 1 1\n",
      "2 7 3 1 1 1\n",
      "3 0 0\n",
      "3 1 1\n",
      "3 1 1 1\n",
      "3 1 1 1 2\n",
      "3 1 1 1 2 4\n",
      "3 3 1\n",
      "3 3 1 1\n",
      "3 3 1 1 1\n",
      "3 3 1 1 1 2\n",
      "3 3 7\n",
      "3 3 7 5\n",
      "3 3 7 5 4\n",
      "3 3 7 5 4 5\n",
      "3 5 6\n",
      "3 5 6 1\n",
      "3 5 6 1 2\n",
      "3 5 6 1 2 3\n",
      "3 5 7\n",
      "3 5 7 0\n",
      "3 5 7 0 0\n",
      "3 5 7 0 0 0\n",
      "3 7 5\n",
      "3 7 5 4\n",
      "3 7 5 4 5\n",
      "3 7 5 4 5 2\n",
      "4 3 5\n",
      "4 3 5 6\n",
      "4 3 5 6 1\n",
      "4 3 5 6 1 2\n",
      "4 5 2\n",
      "4 5 2 6\n",
      "4 5 2 6 7\n",
      "4 5 2 6 7 5\n",
      "4 5 6\n",
      "4 5 6 1\n",
      "4 5 6 1 1\n",
      "4 5 6 1 1 1\n",
      "4 6 2\n",
      "4 6 2 4\n",
      "4 6 2 4 6\n",
      "4 6 2 4 6 5\n",
      "4 6 5\n",
      "4 6 5 4\n",
      "4 6 5 4 5\n",
      "4 6 5 4 5 6\n",
      "5 1 0\n",
      "5 1 0 0\n",
      "5 1 0 0 0\n",
      "5 1 0 0 0 1\n",
      "5 1 7\n",
      "5 1 7 5\n",
      "5 1 7 5 5\n",
      "5 1 7 5 5 7\n",
      "5 2 6\n",
      "5 2 6 7\n",
      "5 2 6 7 5\n",
      "5 2 6 7 5 1\n",
      "5 4 5\n",
      "5 4 5 2\n",
      "5 4 5 2 6\n",
      "5 4 5 2 6 7\n",
      "5 4 5 6\n",
      "5 4 5 6 1\n",
      "5 4 5 6 1 1\n",
      "5 5 7\n",
      "5 5 7 0\n",
      "5 5 7 0 0\n",
      "5 5 7 0 0 0\n",
      "5 6 1\n",
      "5 6 1 1\n",
      "5 6 1 1 1\n",
      "5 6 1 1 1 0\n",
      "5 6 1 2\n",
      "5 6 1 2 3\n",
      "5 6 1 2 3 0\n",
      "5 7 0\n",
      "5 7 0 0\n",
      "5 7 0 0 0\n",
      "5 7 0 0 0 2\n",
      "5 7 0 0 0 4\n",
      "6 1 1\n",
      "6 1 1 1\n",
      "6 1 1 1 0\n",
      "6 1 1 1 0 0\n",
      "6 1 2\n",
      "6 1 2 3\n",
      "6 1 2 3 0\n",
      "6 1 2 3 0 0\n",
      "6 1 5\n",
      "6 1 5 1\n",
      "6 1 5 1 7\n",
      "6 1 5 1 7 5\n",
      "6 2 4\n",
      "6 2 4 6\n",
      "6 2 4 6 5\n",
      "6 2 4 6 5 4\n",
      "6 5 4\n",
      "6 5 4 5\n",
      "6 5 4 5 6\n",
      "6 5 4 5 6 1\n",
      "6 7 5\n",
      "6 7 5 1\n",
      "6 7 5 1 0\n",
      "6 7 5 1 0 0\n",
      "7 0 0\n",
      "7 0 0 0\n",
      "7 0 0 0 2\n",
      "7 0 0 0 2 2\n",
      "7 0 0 0 4\n",
      "7 0 0 0 4 3\n",
      "7 0 6\n",
      "7 0 6 1\n",
      "7 0 6 1 5\n",
      "7 0 6 1 5 1\n",
      "7 2 2\n",
      "7 2 2 1\n",
      "7 2 2 1 1\n",
      "7 2 2 1 1 1\n",
      "7 3 1\n",
      "7 3 1 1\n",
      "7 3 1 1 1\n",
      "7 3 3\n",
      "7 3 3 1\n",
      "7 3 3 1 1\n",
      "7 3 3 1 1 1\n",
      "7 3 3 7\n",
      "7 3 3 7 5\n",
      "7 3 3 7 5 4\n",
      "7 5 1\n",
      "7 5 1 0\n",
      "7 5 1 0 0\n",
      "7 5 1 0 0 0\n",
      "7 5 4\n",
      "7 5 4 5\n",
      "7 5 4 5 2\n",
      "7 5 4 5 2 6\n",
      "7 5 5\n",
      "7 5 5 7\n",
      "7 5 5 7 0\n",
      "7 5 5 7 0 0\n",
      "262\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# verify there are no duplicates in output:\n",
    "for p in feat_names_2:\n",
    "    print(p)\n",
    "print(len(feat_names_2))\n",
    "print(len(feat_names_2) == len(set(feat_names_2)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "# Differences vs original implementation:\n",
    "# -- This uses updated Sk Learn\n",
    "# -- This is initialized correctly\n",
    "# -- This takes last rather than np.array input"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reading input data...\n",
      "Input data extracted.\n"
     ]
    }
   ],
   "source": [
    "import csv\n",
    "import os\n",
    "\n",
    "# Try this approach on the 2k item test corpus:\n",
    "def read_input_data(in_dir):\n",
    "    print(\"Reading input data...\")\n",
    "    feature = 'diatonic_scale_degree'\n",
    "    titles = [filename[:-4] for filename in os.listdir(in_dir)]\n",
    "    # list csv files in 'inpath' dir and read each to a pandas Dataframe using utils.read_csv():\n",
    "    inpaths = [f\"{in_dir}/{filename}\" for filename in os.listdir(in_dir) if filename.endswith(\".csv\")]\n",
    "    # identify csv col names\n",
    "    with open(inpaths[0]) as testfile:\n",
    "        csv_reader = csv.reader(testfile, delimiter=',')\n",
    "        cols = next(csv_reader)\n",
    "        colsmap = {col_name: i for i, col_name in enumerate(cols)}\n",
    "        assert feature in colsmap\n",
    "    # identify index of target column\n",
    "    target_col_idx = colsmap[feature]\n",
    "    # extract target column from all tunes to list\n",
    "    input_data = [\n",
    "        np.genfromtxt(\n",
    "            path,\n",
    "            dtype='str',\n",
    "            delimiter=',',\n",
    "            usecols=target_col_idx,\n",
    "            skip_header=1)\n",
    "        for path in inpaths\n",
    "    ]\n",
    "\n",
    "    data = dict(zip(titles, input_data))\n",
    "    print(\"Input data extracted.\")\n",
    "    return data\n",
    "\n",
    "corpus_inpath = \"//Users/dannydiamond/NUIG/Polifonia/thesession/revised_feat_seq_corpus_no_pickups/feat_seq_accents\"\n",
    "test_inpath = \"/Users/dannydiamond/NUIG/Polifonia/thesession/testing/feat_seq_corpus2k/feat_seq_accents\"\n",
    "raw_data = read_input_data(corpus_inpath)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# inspect input_data\n",
    "print(type(list(raw_data.values())[0]))\n",
    "# for title, seq in raw_data.items():\n",
    "#     print(f'{title}: {seq}')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['3', '4', '3', '2', '3', '4', '1', '2', '3', '4', '3', '2', '3', '4', '1', '2', '1', '6', '1', '6', '1', '6', '1', '2', '1', '6', '1', '6', '1', '6', '1', '2'], ['5', '3', '1', '5', '4', '5', '3', '3', '1', '3', '1', '5', '7', '1', '5', '4', '1', '3', '1', '5', '4', '5', '3', '3', '1', '3', '1', '5', '7', '1', '5', '4', '1', '1', '1', '1', '5', '1', '1', '4', '1', '1', '1', '1', '5', '3', '1', '3', '1', '1', '1', '1', '5', '1', '1', '4', '1', '1', '1', '1', '5', '3', '1', '3', '1']]\n"
     ]
    }
   ],
   "source": [
    "# Convert values in this dict from arrays to lists.\n",
    "input_data = [seq.tolist() for seq in raw_data.values()]\n",
    "print(input_data[:2])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "outputs": [],
   "source": [
    "# method copied from above: vectorize the test input\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "test_vec = CountVectorizer(input='content', lowercase=False, tokenizer=lambda x: x, ngram_range=(3,9), min_df=1, analyzer='word')\n",
    "# corpus_vec = CountVectorizer(input='content', analyzer='word', ngram_range=(3, 9), lowercase=False, tokenizer=lambda x: x, min_df=1)\n",
    "# store all n-gram pattern freqs:\n",
    "test_freq = test_vec.fit_transform(input_data)\n",
    "# store all unique n-gram patterns:\n",
    "test_feat_names = test_vec.get_feature_names_out()\n",
    "test_patterns = np.array([np.array([int(float(ch.strip())) for ch in p.split()], dtype='int16') for p in test_feat_names], dtype='object')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 1 1\n",
      "1 1 1 1\n",
      "1 1 1 1 1\n",
      "1 1 1 1 1 1\n",
      "1 1 1 1 1 1 1\n",
      "1 1 1 1 1 1 1 1\n",
      "1 1 1 1 1 1 1 1 1\n",
      "1 1 1 1 1 1 1 1 2\n",
      "1 1 1 1 1 1 1 1 3\n",
      "1 1 1 1 1 1 1 1 4\n",
      "1 1 1 1 1 1 1 1 5\n",
      "1 1 1 1 1 1 1 1 6\n",
      "1 1 1 1 1 1 1 1 7\n",
      "1 1 1 1 1 1 1 2\n",
      "1 1 1 1 1 1 1 2 1\n",
      "1 1 1 1 1 1 1 2 2\n",
      "1 1 1 1 1 1 1 2 3\n",
      "1 1 1 1 1 1 1 2 4\n",
      "1 1 1 1 1 1 1 2 5\n",
      "1 1 1 1 1 1 1 2 6\n",
      "1 1 1 1 1 1 1 2 7\n",
      "1 1 1 1 1 1 1 3\n",
      "1 1 1 1 1 1 1 3 1\n",
      "1 1 1 1 1 1 1 3 2\n",
      "1 1 1 1 1 1 1 3 3\n",
      "1 1 1 1 1 1 1 3 4\n",
      "1 1 1 1 1 1 1 3 5\n",
      "1 1 1 1 1 1 1 3 7\n",
      "1 1 1 1 1 1 1 4\n",
      "1 1 1 1 1 1 1 4 1\n",
      "1 1 1 1 1 1 1 4 2\n",
      "1 1 1 1 1 1 1 4 3\n",
      "1 1 1 1 1 1 1 4 4\n",
      "1 1 1 1 1 1 1 4 5\n",
      "1 1 1 1 1 1 1 4 6\n",
      "1 1 1 1 1 1 1 4 7\n",
      "1 1 1 1 1 1 1 5\n",
      "1 1 1 1 1 1 1 5 1\n",
      "1 1 1 1 1 1 1 5 2\n",
      "1 1 1 1 1 1 1 5 4\n",
      "1 1 1 1 1 1 1 5 5\n",
      "1 1 1 1 1 1 1 6\n",
      "1 1 1 1 1 1 1 6 1\n",
      "1 1 1 1 1 1 1 6 2\n",
      "1 1 1 1 1 1 1 6 3\n",
      "1 1 1 1 1 1 1 6 5\n",
      "1 1 1 1 1 1 1 6 6\n",
      "1 1 1 1 1 1 1 7\n",
      "1 1 1 1 1 1 1 7 1\n",
      "1 1 1 1 1 1 1 7 2\n",
      "1 1 1 1 1 1 1 7 3\n",
      "1 1 1 1 1 1 1 7 5\n",
      "1 1 1 1 1 1 1 7 6\n",
      "1 1 1 1 1 1 1 7 7\n",
      "1 1 1 1 1 1 2\n",
      "1 1 1 1 1 1 2 1\n",
      "1 1 1 1 1 1 2 1 1\n",
      "1 1 1 1 1 1 2 1 2\n",
      "1 1 1 1 1 1 2 1 5\n",
      "1 1 1 1 1 1 2 1 6\n",
      "1 1 1 1 1 1 2 2\n",
      "1 1 1 1 1 1 2 2 1\n",
      "1 1 1 1 1 1 2 2 2\n",
      "1 1 1 1 1 1 2 2 3\n",
      "1 1 1 1 1 1 2 2 5\n",
      "1 1 1 1 1 1 2 2 7\n",
      "1 1 1 1 1 1 2 3\n",
      "1 1 1 1 1 1 2 3 1\n",
      "1 1 1 1 1 1 2 3 4\n",
      "1 1 1 1 1 1 2 4\n",
      "1 1 1 1 1 1 2 4 1\n",
      "1 1 1 1 1 1 2 4 2\n",
      "1 1 1 1 1 1 2 4 4\n",
      "1 1 1 1 1 1 2 4 5\n",
      "1 1 1 1 1 1 2 4 7\n",
      "1 1 1 1 1 1 2 5\n",
      "1 1 1 1 1 1 2 5 1\n",
      "1 1 1 1 1 1 2 5 2\n",
      "1 1 1 1 1 1 2 5 3\n",
      "1 1 1 1 1 1 2 5 4\n",
      "1 1 1 1 1 1 2 5 6\n",
      "1 1 1 1 1 1 2 5 7\n",
      "1 1 1 1 1 1 2 6\n",
      "1 1 1 1 1 1 2 6 1\n",
      "1 1 1 1 1 1 2 6 3\n",
      "1 1 1 1 1 1 2 6 5\n",
      "1 1 1 1 1 1 2 7\n",
      "1 1 1 1 1 1 2 7 1\n",
      "1 1 1 1 1 1 2 7 5\n",
      "1 1 1 1 1 1 2 7 7\n",
      "1 1 1 1 1 1 3\n",
      "1 1 1 1 1 1 3 1\n",
      "1 1 1 1 1 1 3 1 1\n",
      "1 1 1 1 1 1 3 1 2\n",
      "1 1 1 1 1 1 3 1 3\n",
      "1 1 1 1 1 1 3 1 6\n",
      "1 1 1 1 1 1 3 2\n",
      "1 1 1 1 1 1 3 2 1\n",
      "1 1 1 1 1 1 3 2 2\n",
      "1 1 1 1 1 1 3 2 5\n",
      "2177751\n",
      "True\n",
      "True\n"
     ]
    }
   ],
   "source": [
    "# verify there are no duplicates in output:\n",
    "for p in test_feat_names[:100]:\n",
    "    print(p)\n",
    "print(len(test_feat_names))\n",
    "print(len(test_feat_names) == len(set(test_feat_names)))\n",
    "print(len(test_patterns) == len(set(test_feat_names)))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}